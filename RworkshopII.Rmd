---
title: "Hello, R!"
author: "Yue Hu's R Workshop Series II"
output:
  ioslides_presentation:
    self_contained: yes
    logo: image/logo.gif
    transition: faster
    widescreen: yes
    slidy_presentation:
    incremental: yes
---
# Preface
## What Are Covered in This Workshop Series 
* [A overview of R](https://rpubs.com/sammo3182/Rintro) 
* [Data manipulation (input/output, row/column selections, etc.)](https://rpubs.com/sammo3182/Rintro) 
* **Descriptive and binary hypotheses (summary, correlation, t-test, etc.)**
* **Multiple regression (OLS, GLS, MLM, etc.)**
* Multilevel Regression
* Presentation (table, graph)



## Data
```{r message=FALSE}
library(dplyr)
baby <- filter(babynames::babynames, year > 2010)
head(baby)
```

****
```{r message=FALSE}
library(dplyr)
glimpse(baby)
```


## Descriptive analysis {.smaller}
For a dataset or a numeric vector
```{r}
summary(baby)
```
One can use `mean`, `sd`, `max`, `min`, etc. to extract specific descriptive statistics.

## Descriptive analysis (continue) {.build}
`dplyr::summarise` <span style="color:green">Tip</span>

<div class="notes">
`%>%` is a piper connector embedded in `dplyr` package. One can use it to avoid too complicated embedding coding: e.g., You want to see the maximum value of the mileage for carts with 6 cylinders. The regular code can be written as:
```{r eval= FALSE}
max(dplyr::select(filter(baby, year == 2013), n))
```
With the piper connector, you can write as:

```{r eval = F}
baby %>% 
  filter(year == 2013) %>% 
  dplyr::select(n) %>% 
  max
```

</div>

```{r}
baby %>% count(sex)
```
****
```{r}
baby %>% group_by(sex) %>% summarise(sum = sum(n))
```


## Descriptive analysis (continue) {.build}
* For categorical vectors

```{r}
table(baby$sex)
```

* For observation number
```{r}
nrow(baby)
```




## Data manipulation{.build}
* Create a variable into the dataset (<span style="color:green">Tip</span>)

```{r}
id <- baby$id <- c(1:nrow(baby)) # create an "ID" variable
baby[1:5,] %>% add_rownames("id") # add rowname 
```

<div class="notes">
Obviously, variables can be immediately overwrite without any specific setting. 

It is convenient but also <span style="color:purple">risky</span>.
</div>

****

* Remove a variable from the dataset

```{r}
names(baby)
baby$id <- NULL
names(baby)
```

* Remove variable, result, function, or data from the environment

```{r}
rm(id)
```



## Wrap Up 
* Description: `summary()`, `table()`, `ncol()`, `nrow()`, 
    + More specific: `mean`, `sd`, `max`, `min`, etc.
    + More manipulation is allowed with `dplyr` functions.
* Manipulation: 
    + create: `baby$newvar <- ...`
    + Remove: `baby$newvar <- NULL`; `rm()`
* There are also [`apply` family](http://www.r-bloggers.com/r-tutorial-on-the-apply-family-of-functions/) functions for with batching management of data.



# Hypothesis Tests

## Binary Tests: Difference of mean

$H_{0}: \bar{prop.male} = \bar{prop.female},\ \alpha = .05$

```{r}
t.test(baby$n[baby$sex == "M"], baby$n[baby$sex == "F"]) 
```

----

`t.test` offers arguments `alternative`, `mu`, `paired`, and `conf.level` for users to change in two-tail/one-tail test, parameter mean, independent/paired comparison, and $\alpha$.

```{r}
# one side, cyl > gear, alpha = .01
t.test(baby$n[baby$sex == "M"], baby$n[baby$sex == "F"],
       alternative = "greater", conf.level = .99)     
```

****
```{r}
# comparing with the parameter (true value)
t.test(baby$n[baby$sex == "M"], mu = mean(baby$n))   # the true mean is 6.
```



## Binary Tests: Correlation
$H_{0}: \rho_{(cyl,gear)} = 0,\ \alpha = .05$

```{r}
cor.test(baby$n, baby$prop)
```

****

`cor.test` offers various arguments as in `t.test` for more specific settings. Moreover, users can use the `method` argument to set the method to calculate the correlations, "Pearson", "Kendall", or "Spearman." (<span style="color:green">Tip</span>)

```{r warning=FALSE}
cor.test(baby$n, baby$prop, conf.level = .99)
# cor.test(~ baby$n + baby$prop, conf.level = .99)
```

<div class="notes">
Do I have to type the `baby$` every time? 

* No you don't.
    + It offers a potential for cross-dataset operation, though.
    + Use `within()`: e.g., `within(baby, cor.test(n, prop))`
    + Use `attach()` (not recommonded)
</div>


----

```{r}
with(baby, cor.test(~ n + prop, subset = (year == 2013)))
```


----

We can get the correlation matrix, too:
```{r}
cor(baby[,4:5])
```

## Binary Tests: ANOVA{.smaller}
One way or two way ANOVA: (<span style="color:green">Tip</span>)

```{r}
aov_one <- aov(prop ~ sex, data = baby) #one-way
aov_two <- aov(prop ~ sex + year, data = baby) #two-way

summary(aov_one); summary(aov_two)
```

<div class="notes">
Sometimes, `summary` offers more organized results than `print`:

```{r}
aov_one #print it
summary(aov_one) #summarize it
```

</div>

## Wrap up
* T-test: `t.test(x, y = NULL, alternative = c("two.sided", "less", "greater"), mu = 0, paired = FALSE, conf.level = 0.95, ...)`

* Correlation: `cor.test(x, y, alternative = c("two.sided", "less", "greater"), method = c("pearson", "kendall", "spearman"), conf.level = 0.95, continuity = FALSE, ...) `

* ANOVA: `aov(formula, data = NULL, ...)`

----

Next: more commands are coming: multiple regressions~

+ <div class="centered">
![core](http://i.123g.us/c/bus_appreciate/card/101834.gif)
</div>

# Multiple Regression
## Ordinary Linear Regression{.build}
* we are detecting the contributions of the cylinders, horsepower, and weight of the care (Xs) to the mileage (Y): 
    
```{r}
lm_ols <- lm(prop ~ n + sex + year, data = baby)
``` 


## The result {.smaller}

```{r}
summary(lm_ols)
```  

  
## Nonlinear transformation
ln, square, exponential, or inverse

```{r}
lm_tran <- lm(exp(prop) ~ log(n) + sex + I(year - min(year)) + 
                I((year - min(year))^2), data = baby)
```


## The result {.smaller}

```{r}
summary(lm_tran)
```

## Break the factor variable

If we want to include a categorical variable into the regression, R will break it into binary variables for you.

```{r message=FALSE}
baby$year_f <- baby$year - 2010 
baby$year_f <- factor(baby$year_f, levels = 1:3, labels = c("2011", "2012", "2013"))
str(baby$year_f)  

lm_f <- lm(prop ~ n + sex + year_f, data = baby)

```

## The result {.smaller}

```{r}
summary(lm_f)
```

## Interaction
Two ways to write the model
```{r}
lm_in <- lm(prop ~ n + sex * year, data = baby)
# lm_in <- lm(prop ~ n + sex + year + sex:year, data = baby)
```

## The result {.smaller}
```{r}
summary(lm_in)
```

## Post-estimate diagnoses: Residural
  
```{r fig.height=3.5, fig.align="center"}
res <- resid(lm_ols)
# res <- baby$prop - predict(lm_ols)

res[1:5]
```

****

```{r}
plot(lm_ols, which = 1) # R offer 6 types of plots for post-estimation diagnosis. 
```

Use `which` to control for which plot you want to show. The default is to show four.


## Post-estimate diagnoses: Outliers
```{r warning=FALSE}
library(car) # Bonferonni p-value for most extreme obs

outlierTest(lm_ols)
```

----
```{r}
qqPlot(lm_ols)  #qq plot for studentized resid 
```


## Post-estimate diagnoses: CLRM Properties{.build}
* Heteroscedasticity 

```{r}
ncvTest(lm_ols) 
```

* Multicollinearity
```{r}
vif(lm_ols) 
```

## Logit
The process to run a logit is largely the same as running an OLS, except for the function name and certain arguments. 

```{r}
baby$female <- ifelse(baby$sex == "M", 0, 1)
logit <- glm(female ~ n + year, data = baby, family = "binomial")
```

## The result{.smaller}

```{r}
summary(logit)
```

## Interpretation: Margin
Marginal effect

```{r message=FALSE}
library(mfx)
logit_m <- logitmfx(female ~ n + year, data = baby) 
logit_m
```

## Interpretation: Predicted probability
Predicted Probability when `year` changes from 2011 to 2013.
```{r}
# Step 1: creat an aggregate data 
baby_fake <- with(baby, data.frame(year = 2011:2013, n = mean(n)))
# Step 2: predict based on the new data
logit_pp <- cbind(baby_fake, predict(logit, newdata = baby_fake, type = "link", se = TRUE))
# Step 3: convert to probability 
logit_pp <- within(logit_pp, {pp <- plogis(fit) 
                                lb <- plogis(fit - 1.96 * se.fit)
                                ub <- plogis(fit + 1.96 * se.fit)})
logit_pp[, 6:8]
```


## Wrap Up
* OLS: `lm(Y ~ X, data = data)`
    + Non-linear transformations: `I(X^2)`, `exp(X)`, `log(X)`.
    + Using factor variable: R will handle that for you.
    + Interaction: `lm(Y ~ X * Z, data = data)`.
    + Post-estimate diagnoses: `resid()`, `outlierTest()`, `qqPlot()`, `ncvTest()`, `vif()`, `durbinWatsonTest()`
* Logit: `glm(Y ~ X, data = data, family = "binomial")`
    + Margins: using `mfx::logitmfx`
    + Predict probabilty: 
        + Step 1: create an aggregate data
        + Step 2: predict the log odds
        + Step 3: transfer to probability
        
----

Next: How to effectively present the results?

<div class="centered">
![present](http://media.giphy.com/media/HQjYmJ2OGSNeE/giphy.gif)
</div>

Come to the R-series Lecture III: Presentation with R!    

## External Sources
* Q&A Blogs: 
    + http://stackoverflow.com/questions/tagged/r
    + https://stat.ethz.ch/mailman/listinfo/r-help

* Blog for new stuffs: http://www.r-bloggers.com/

* Workshops: http://ppc.uiowa.edu/node/3608
* Consulting service: http://ppc.uiowa.edu/node/3385/


----

<div class = "center">
<img src="http://www.junipercivic.com/images/Berry/thats-all-folks.jpg" height = "550" />
</div>

